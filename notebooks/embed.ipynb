{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anantajit/data/Bluesky-Discourse-Forecasting/.venv/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from sentence_transformers import sentencetransformer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /data/home/anantajit/Bluesky-Discourse-Forecasting/notebooks\n",
      "                                                text                 createdAt\n",
      "0                           Happy Birthday Tom Baker  2025-01-20T08:21:29.582Z\n",
      "1  Been playing Astrobot this week-end with my da...  2025-01-20T08:21:30.788Z\n",
      "2                    #MLKDay\\n#MartinLutherKingJrDay  2025-01-20T08:21:30.771Z\n",
      "3  Iâ€™m locked and loaded, fully customized!! Happ...  2025-01-20T08:21:29.713Z\n",
      "4                                        No need ðŸ™ƒðŸ˜‚ðŸ¥°  2025-01-20T08:21:30.733Z\n"
     ]
    }
   ],
   "source": [
    "# data loader - use only Jan 20th\n",
    "import pandas as pd \n",
    "from os import getcwd\n",
    "\n",
    "print(f\"Working Directory: {getcwd()}\")\n",
    "\n",
    "df = pd.read_parquet(\"../data/2025-01-20.parquet\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\", trust_remote_code=True)\n",
    "model.to(\"cuda:1\")\n",
    "# In case you want to reduce the maximum length:\n",
    "model.max_seq_length = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Block count:   0%|          | 0/351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Block count: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [8:08:49<00:00, 83.56s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "BLOCK_SIZE = 10_000\n",
    "\n",
    "for i in tqdm(range(0, len(df), BLOCK_SIZE), desc=\"Block count\"):\n",
    "    slice = df[:][i:i + BLOCK_SIZE]\n",
    "\n",
    "    tweet_embeddings = model.encode(slice['text'].tolist(), device=DEVICE, max_length=300)\n",
    "    slice['embeddings'] = tweet_embeddings.tolist()\n",
    "    \n",
    "    slice.to_parquet(f\"../data/embeddings/{i//BLOCK_SIZE:03d}.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
